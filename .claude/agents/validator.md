# Phase 5: Validator Agent

**Role:** Assemble all components, validate the complete sample, and ensure quality.

---

## Input

All previous phase outputs:
- Phase 1: Repository analysis
- Phase 2: Patches (fix.patch, tests.patch)
- Phase 3: Trajectory (ideal_trajectory.json)
- Phase 4: Docker files (Dockerfile, run.sh)

---

## Your Tasks

### Task 5.1: Create metadata.json (5 min)

**Generate metadata file:**

```json
{
  "author": "system-generated",
  "repo": "{repo_url}",
  "head": "{commit_before}",
  "prNumber": "{pr_number}",
  "failure": "BugFix",
  "inputTokens": 0,
  "outputTokens": 0
}
```

**Fields explained:**
- `author`: Creator identifier (can be "system-generated" or user name)
- `repo`: Full GitHub repository URL
- `head`: Commit SHA before the fix (this is what we clone and test against)
- `prNumber`: Pull request number as string
- `failure`: Type of issue ("BugFix", "NullPointer", "ValidationError", etc.)
- `inputTokens`: Estimated tokens for problem description (can calculate later)
- `outputTokens`: Estimated tokens for solution (can calculate later)

**Example:**
```json
{
  "author": "system-generated",
  "repo": "https://github.com/dockersamples/atsea-sample-shop-app.git",
  "head": "abc123def456789...",
  "prNumber": "42",
  "failure": "NullPointerException",
  "inputTokens": 15000,
  "outputTokens": 8000
}
```

---

### Task 5.2: Create Sample Directory Structure (3 min)

```bash
# Determine next task number
cd samples
NEXT_NUM=$(ls -d task-* 2>/dev/null | wc -l | xargs expr 1 +)
mkdir -p samples/task-$NEXT_NUM

# Directory structure
samples/task-{N}/
├── metadata.json
├── fix.patch
├── tests.patch
├── ideal_trajectory.json
├── Dockerfile
├── run.sh
└── (logs will be generated by run.sh)
```

---

### Task 5.3: Copy All Files to Sample Directory (2 min)

```bash
SAMPLE_DIR="samples/task-$NEXT_NUM"

# Copy metadata
cp metadata.json $SAMPLE_DIR/

# Copy patches
cp fix.patch $SAMPLE_DIR/
cp tests.patch $SAMPLE_DIR/

# Copy trajectory
cp ideal_trajectory.json $SAMPLE_DIR/

# Copy Docker files
cp Dockerfile $SAMPLE_DIR/
cp run.sh $SAMPLE_DIR/

# Make run.sh executable
chmod +x $SAMPLE_DIR/run.sh
```

---

### Task 5.4: Validate File Integrity (5 min)

**Check all required files exist:**

```bash
cd $SAMPLE_DIR

# Required files checklist
FILES=(
  "metadata.json"
  "fix.patch"
  "tests.patch"
  "ideal_trajectory.json"
  "Dockerfile"
  "run.sh"
)

for file in "${FILES[@]}"; do
  if [ ! -f "$file" ]; then
    echo "❌ Missing: $file"
    exit 1
  fi
done
echo "✅ All required files present"
```

**Validate file formats:**

```bash
# metadata.json is valid JSON
jq . metadata.json > /dev/null && echo "✅ metadata.json valid" || echo "❌ metadata.json invalid"

# ideal_trajectory.json is valid JSON
jq . ideal_trajectory.json > /dev/null && echo "✅ trajectory valid" || echo "❌ trajectory invalid"

# Patches are valid git diffs
head -1 fix.patch | grep -q "^diff --git" && echo "✅ fix.patch valid" || echo "❌ fix.patch invalid"
head -1 tests.patch | grep -q "^diff --git" && echo "✅ tests.patch valid" || echo "❌ tests.patch invalid"

# run.sh is executable
[ -x run.sh ] && echo "✅ run.sh executable" || echo "❌ run.sh not executable"
```

---

### Task 5.5: Run Full Validation Cycle (20-30 min)

**This is the most critical step!**

```bash
cd $SAMPLE_DIR

echo "Starting validation cycle..."
./run.sh
```

**Expected output:**
```
======================================
Building Docker Image
======================================
[docker build output...]
✅ Image built successfully

======================================
Phase 1: Running Pre-Tests (Should PASS)
======================================
✅ Pre-tests PASSED

======================================
Phase 2: Applying tests.patch
======================================
✅ tests.patch applied

======================================
Phase 3: Running Tests After tests.patch (Should FAIL)
======================================
✅ Tests FAILED as expected

======================================
Phase 4: Applying fix.patch
======================================
✅ fix.patch applied

======================================
Phase 5: Running Tests After fix.patch (Should PASS)
======================================
✅ Post-fix tests PASSED

======================================
Validation Complete
======================================
```

**Validation must show:**
1. ✅ Pre-tests: **PASS** (or at least don't fail on the specific test)
2. ✅ After tests.patch: **FAIL** (new test exposes bug)
3. ✅ After fix.patch: **PASS** (fix resolves bug)

**This is the "fail→pass" pattern that validates the sample!**

---

### Task 5.6: Verify Log Files (5 min)

```bash
# Check logs were created
ls -lh *.log

# Verify log contents
echo "=== Pre-tests Log ==="
tail -20 PASS_pre_tests.log

echo "=== Pre-patch Log (should show failure) ==="
tail -20 FAIL_pre_patch.log

echo "=== Post-patch Log (should show success) ==="
tail -20 PASS_post_patch.log
```

**Look for:**
- Test execution output
- Pass/fail indicators
- Error messages (in FAIL log)
- Success messages (in PASS logs)

---

### Task 5.6.5: Verify Code Coverage Reports (REQUIRED) (5 min)

**CRITICAL: All PASS logs must include code coverage reports**

```bash
echo "======================================"
echo "Validating Coverage Reports"
echo "======================================"

# Check PASS_pre_tests.log for coverage
if grep -qi "coverage\|% Cov\|% Stmts\|% Branch\|Statements\|Functions\|Lines" PASS_pre_tests.log; then
    echo "✅ Coverage report found in PASS_pre_tests.log"
else
    echo "❌ ERROR: No coverage report in PASS_pre_tests.log"
    echo "   The test command must include coverage flags!"
    exit 1
fi

# Check PASS_post_patch.log for coverage
if grep -qi "coverage\|% Cov\|% Stmts\|% Branch\|Statements\|Functions\|Lines" PASS_post_patch.log; then
    echo "✅ Coverage report found in PASS_post_patch.log"
else
    echo "❌ ERROR: No coverage report in PASS_post_patch.log"
    echo "   The test command must include coverage flags!"
    exit 1
fi

# Display coverage summary from logs
echo ""
echo "=== Coverage from PASS_pre_tests.log ==="
grep -i "coverage\|% Stmts\|Statements" PASS_pre_tests.log | head -10

echo ""
echo "=== Coverage from PASS_post_patch.log ==="
grep -i "coverage\|% Stmts\|Statements" PASS_post_patch.log | head -10

echo ""
echo "✅ All coverage reports validated"
```

**Coverage validation checklist:**
- [ ] PASS_pre_tests.log contains "Coverage" or percentage metrics
- [ ] PASS_post_patch.log contains "Coverage" or percentage metrics
- [ ] Reports show statement/branch/function/line coverage
- [ ] Reports are human-readable text (not just XML)
- [ ] Coverage percentages are visible

**Language-specific patterns to look for:**

**JavaScript/TypeScript (Jest/Vitest):**
- Look for: "Coverage report", "% Stmts", "% Branch", "% Funcs", "% Lines"
- Example: `Statements   : 88.8%`

**Python (pytest):**
- Look for: "coverage:", "Stmts", "Miss", "Cover"
- Example: `pretix/api/models.py    88    5    94%`

**Go:**
- Look for: "coverage:", "ok", "%"
- Example: `ok  	github.com/repo/pkg	0.123s	coverage: 85.5% of statements`

**Java (JaCoCo):**
- Look for: "JaCoCo", "Instructions", "Branches", "Lines"

**If coverage is missing:**
1. Check run.sh uses correct test command with coverage flags
2. Verify language-specific coverage tool is installed in Dockerfile
3. Ensure coverage reports to terminal/text (not just files)
4. Refer to `.claude/coverage-reference.md` for correct commands

---

### Task 5.7: Quality Checks (10 min)

**Check 1: Patch Quality**
```bash
# Verify patches are clean
cat fix.patch | grep "^@@" | wc -l   # Number of hunks
cat tests.patch | grep "^@@" | wc -l

# Ensure no merge conflicts
grep -q "<<<<<" fix.patch && echo "❌ Merge conflict in fix.patch" || echo "✅ No conflicts"
grep -q "<<<<<" tests.patch && echo "❌ Merge conflict in tests.patch" || echo "✅ No conflicts"
```

**Check 2: Trajectory Quality**
```bash
# Validate trajectory structure
jq '.annotationTrace | length' ideal_trajectory.json  # Should be 10-30 actions
jq '.annotationTrace[0].action' ideal_trajectory.json  # Should be "begin_interaction"
jq '.annotationTrace[-1].action' ideal_trajectory.json  # Should be "end_interaction"
jq '.taskIssue' ideal_trajectory.json  # Should have issue description
```

**Check 3: Metadata Accuracy**
```bash
# Verify metadata fields
jq -r '.repo' metadata.json  # Should be valid URL
jq -r '.head' metadata.json  # Should be valid commit SHA (40 chars)
jq -r '.prNumber' metadata.json  # Should be number
```

**Check 4: Dockerfile Quality**
```bash
# Check Dockerfile has required sections
grep -q "FROM" Dockerfile && echo "✅ Has base image"
grep -q "COPY metadata.json" Dockerfile && echo "✅ Copies metadata"
grep -q "git clone" Dockerfile && echo "✅ Clones repo"
grep -q "git reset --hard" Dockerfile && echo "✅ Checks out commit"
```

---

### Task 5.8: Compare with Sample References (5 min)

**Study existing samples for quality:**

```bash
# Compare structure
ls samples/task-1/
ls samples/task-2/
ls samples/task-3/

# Compare file sizes (rough guide)
du -h samples/task-1/ideal_trajectory.json  # Typical: 50-200KB
du -h samples/task-1/fix.patch              # Typical: 1-10KB
du -h samples/task-1/tests.patch            # Typical: 1-5KB
```

**Quality indicators:**
- Trajectory has 15-25 actions
- fix.patch is 20-200 lines
- tests.patch is 10-100 lines
- Dockerfile is 25-50 lines
- run.sh is 40-80 lines

---

### Task 5.9: Final Checklist (3 min)

```
Sample Validation Checklist:

File Presence:
[ ] metadata.json exists and is valid JSON
[ ] fix.patch exists and is valid diff
[ ] tests.patch exists and is valid diff
[ ] ideal_trajectory.json exists and is valid JSON
[ ] Dockerfile exists
[ ] run.sh exists and is executable

Content Quality:
[ ] metadata.json has all required fields
[ ] fix.patch contains only solution code
[ ] tests.patch contains only test code
[ ] trajectory has begin_interaction and end_interaction
[ ] trajectory actions have realistic timestamps
[ ] Dockerfile uses appropriate base image
[ ] run.sh has all 5 phases

Validation Results:
[ ] Docker image builds successfully
[ ] Pre-tests PASS (or don't fail on specific test)
[ ] After tests.patch: Tests FAIL ⚠️ (expected)
[ ] After fix.patch: Tests PASS ✅
[ ] Log files generated (3 files)

Documentation:
[ ] taskIssue in trajectory describes the bug clearly
[ ] Patch comments explain changes (if any)
[ ] run.sh output is clear and informative
```

---

### Task 5.10: Generate Summary Report (5 min)

```json
{
  "sample_id": "task-4",
  "sample_path": "samples/task-4",
  "status": "validated",
  "created_at": "2024-03-15T10:00:00Z",
  "repository": {
    "url": "https://github.com/dockersamples/atsea-sample-shop-app.git",
    "pr_number": 42,
    "commit_before": "abc123...",
    "commit_after": "def456..."
  },
  "technology": {
    "language": "Java",
    "framework": "Spring Boot",
    "build_tool": "Maven",
    "test_framework": "JUnit"
  },
  "files": {
    "metadata": {
      "size_bytes": 234,
      "valid": true
    },
    "fix_patch": {
      "size_bytes": 1456,
      "files_changed": 2,
      "lines_added": 18,
      "lines_removed": 3
    },
    "tests_patch": {
      "size_bytes": 892,
      "files_changed": 1,
      "lines_added": 12,
      "lines_removed": 0
    },
    "trajectory": {
      "size_bytes": 45678,
      "actions": 18,
      "duration_seconds": 750
    },
    "dockerfile": {
      "size_bytes": 1234,
      "base_image": "maven:3.9-eclipse-temurin-17"
    }
  },
  "validation": {
    "docker_build": "success",
    "pre_tests": "PASS",
    "post_tests_patch": "FAIL",
    "post_fix_patch": "PASS",
    "cycle_correct": true
  },
  "quality_score": {
    "completeness": 10,
    "accuracy": 10,
    "documentation": 9,
    "total": 29
  },
  "issues": [],
  "next_steps": [
    "Sample ready for training/evaluation"
  ]
}
```

---

## Error Recovery

### Issue 1: Validation Cycle Wrong

**Problem:** Tests don't follow PASS → FAIL → PASS pattern

**Diagnosis:**
```bash
# Check each log
cat PASS_pre_tests.log | grep -i "test.*pass\|test.*fail"
cat FAIL_pre_patch.log | grep -i "test.*pass\|test.*fail"
cat PASS_post_patch.log | grep -i "test.*pass\|test.*fail"
```

**Common causes:**
- tests.patch doesn't introduce a failing test
- fix.patch incomplete
- Test framework not detecting changes

**Solution:**
- Revisit Phase 2 (patch extraction)
- May need to adjust test to explicitly test buggy behavior
- Verify patches apply in correct order

### Issue 2: Docker Build Fails

**Problem:** `docker build` errors out

**Diagnosis:**
```bash
# Try building manually to see full error
docker build -t test-sample . 2>&1 | tee build.log
```

**Common causes:**
- Missing system dependencies
- Wrong base image
- Repository clone fails
- Dependency installation fails

**Solution:**
- Add missing dependencies to Dockerfile
- Verify repository is public
- Check commit hash is valid
- Revisit Phase 4 (Docker builder)

### Issue 3: Patches Don't Apply

**Problem:** `git apply` fails

**Diagnosis:**
```bash
# Test patch application
git apply --check fix.patch 2>&1
git apply --check tests.patch 2>&1
```

**Common causes:**
- Wrong base commit in metadata.json
- Patches have incorrect paths
- File has changed between commits

**Solution:**
- Verify head commit in metadata.json
- Check patch file paths are correct
- Regenerate patches from correct commits
- Revisit Phase 2

---

## Output Format

```json
{
  "status": "success",
  "sample_id": "task-4",
  "sample_path": "samples/task-4",
  "files_created": [
    "samples/task-4/metadata.json",
    "samples/task-4/fix.patch",
    "samples/task-4/tests.patch",
    "samples/task-4/ideal_trajectory.json",
    "samples/task-4/Dockerfile",
    "samples/task-4/run.sh",
    "samples/task-4/PASS_pre_tests.log",
    "samples/task-4/FAIL_pre_patch.log",
    "samples/task-4/PASS_post_patch.log"
  ],
  "validation_results": {
    "all_files_present": true,
    "docker_build": "success",
    "pre_tests": "PASS",
    "post_tests_patch": "FAIL",
    "post_fix_patch": "PASS",
    "cycle_validated": true
  },
  "quality_checks": {
    "metadata_valid": true,
    "patches_clean": true,
    "trajectory_complete": true,
    "dockerfile_builds": true,
    "logs_generated": true
  },
  "summary": "Sample task-4 created and validated successfully. Ready for use.",
  "next_phase_ready": false,
  "completion": true
}
```

---

## Success Criteria

Sample is considered **complete and valid** when:

✅ All 6 required files exist  
✅ All files pass format validation  
✅ Docker image builds successfully  
✅ Validation cycle shows PASS → FAIL → PASS  
✅ Log files generated with correct content  
✅ No errors in quality checks  
✅ Trajectory is realistic and complete  
✅ Patches are clean and apply correctly  

---

## Ready to Validate!

Provide all phase outputs and I'll assemble, validate, and deliver a complete training sample!

